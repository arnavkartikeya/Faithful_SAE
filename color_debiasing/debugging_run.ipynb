{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b018796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('../../')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Faithful_SAE.models import Faithful_SAE \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import ColorMNISTCNN\n",
    "from data import BiasedColorizedMNIST, UnbiasedColorizedMNIST, CNNActivationDatasetWithColors\n",
    "from train_models import train_model, train_cnn_sae_with_color_conditioning\n",
    "from data import create_biased_dataset, create_unbiased_dataset\n",
    "from torch.utils.data import random_split\n",
    "from run import create_ablated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b326785-c701-46b8-b2a9-746b43f561dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'concepts': 1024, 'cond_lam': 0.5016787095206698, 'faithful_lam': 1.168462365792744, 'k': 16, 'l1_lam': 1.447664740275463, 'recon_lam': 1.7964982558265474, 'sae_lr': 0.0007095408650229278, 'sae_steps': 32000}\n",
      "Loaded 6711 unbiased images\n",
      "\n",
      "Unbiased Dataset Statistics:\n",
      "----------------------------------------\n",
      "Per-digit breakdown:\n",
      "  Digit 0: 321 red, 324 green (total: 645)\n",
      "  Digit 1: 377 red, 392 green (total: 769)\n",
      "  Digit 2: 353 red, 320 green (total: 673)\n",
      "  Digit 3: 350 red, 326 green (total: 676)\n",
      "  Digit 4: 363 red, 315 green (total: 678)\n",
      "  Digit 5: 301 red, 291 green (total: 592)\n",
      "  Digit 6: 322 red, 324 green (total: 646)\n",
      "  Digit 7: 345 red, 360 green (total: 705)\n",
      "  Digit 8: 308 red, 338 green (total: 646)\n",
      "  Digit 9: 332 red, 349 green (total: 681)\n",
      "\n",
      "Overall:\n",
      "  Total red images: 3372\n",
      "  Total green images: 3339\n",
      "  Total images: 6711\n",
      "  Red/Green ratio: 0.50/0.50\n"
     ]
    }
   ],
   "source": [
    "import yaml \n",
    "device = 'cuda' \n",
    "with open('best_run_artifacts/best_config.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "print(data)\n",
    "\n",
    "cnn = ColorMNISTCNN(input_size=28).to(device)\n",
    "sae = Faithful_SAE(input_dim=128, latent_dim=data['concepts'], hidden_dim=64, k=data['k'], use_topk=True).to(device)\n",
    "\n",
    "cnn_dict = torch.load('best_run_artifacts/cnn_model.pth') \n",
    "sae_dict = torch.load('best_run_artifacts/sae_color_good_one.pth') \n",
    "\n",
    "cnn.load_state_dict(cnn_dict)\n",
    "sae.load_state_dict(sae_dict) \n",
    "\n",
    "\n",
    "ablated_model = create_ablated_model(cnn, sae, indices_to_ablate=[0, 1], device=device)\n",
    "ablated_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "unbiased_val_dataset = UnbiasedColorizedMNIST('../../colorized-MNIST/testing')\n",
    "unbiased_val_loader = DataLoader(unbiased_val_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f210588-f85b-4e88-8ad9-2fffd6851953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5108031589926986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in unbiased_val_loader:\n",
    "        outputs = ablated_model(images.to(device))\n",
    "        preds = torch.max(outputs, 1)[1]\n",
    "        correct += (preds == labels.to(device)).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct/total}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5d582ff-c12e-4def-b2e1-fe1f075b68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sae_replaced_model(original_model, sae, device):\n",
    "    \"\"\"\n",
    "    Creates a new model where the FC1 layer is fully REPLACED by the\n",
    "    SAE's effective encoder.\n",
    "    \"\"\"\n",
    "    # Create a deep copy to avoid altering the original model\n",
    "    sae_replaced_model = type(original_model)()\n",
    "    sae_replaced_model.load_state_dict(original_model.state_dict())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # The new weights are simply the SAE's effective encoder\n",
    "        new_weights = sae.effective_encoder().to(device)\n",
    "        \n",
    "        # Transpose and assign to the new model's fc1 layer\n",
    "        sae_replaced_model.fc1.weight.data = new_weights.T.clone()\n",
    "    \n",
    "    sae_replaced_model.to(device)\n",
    "    return sae_replaced_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cc1d065-cc1d-4281-aba3-237ed7c07ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluating models...\n",
      "\n",
      "--- Accuracy Comparison: Original vs. Ablated ---\n",
      "Partition       | Original Model         | Ablated Model          | Difference  \n",
      "================================================================================\n",
      "Overall         | 3197/6711 (47.6%)      | 3428/6711 (51.1%)      | +3.44%\n",
      "Red Low         | 1698/1764 (96.3%)      | 1522/1764 (86.3%)      | -9.98%\n",
      "Red High        | 0/1608 (0.0%)          | 335/1608 (20.8%)       | +20.83%\n",
      "Green Low       | 0/1677 (0.0%)          | 126/1677 (7.5%)        | +7.51%\n",
      "Green High      | 1499/1662 (90.2%)      | 1445/1662 (86.9%)      | -3.25%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def create_sae_replaced_model(original_model, sae, device):\n",
    "    \"\"\"\n",
    "    Creates a new model where the FC1 layer is fully REPLACED by the\n",
    "    SAE's effective encoder.\n",
    "    \"\"\"\n",
    "    # Create a deep copy to avoid altering the original model\n",
    "    sae_replaced_model = type(original_model)()\n",
    "    sae_replaced_model.load_state_dict(original_model.state_dict())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # The new weights are simply the SAE's effective encoder\n",
    "        new_weights = sae.effective_encoder().to(device)\n",
    "        \n",
    "        # Transpose and assign to the new model's fc1 layer\n",
    "        sae_replaced_model.fc1.weight.data = new_weights.T.clone()\n",
    "    \n",
    "    sae_replaced_model.to(device)\n",
    "    return sae_replaced_model\n",
    "\n",
    "    \n",
    "# --- Assumed variables ---\n",
    "# cnn: Your original trained CNN model\n",
    "# ablated_model: The model created with create_ablated_model\n",
    "# unbiased_val_loader: The DataLoader for the unbiased validation set\n",
    "# device: Your 'cuda' or 'cpu' device\n",
    "\n",
    "# --- Evaluation Setup ---\n",
    "model_dict = {'Original': cnn, 'Ablated': ablated_model}\n",
    "partitions = ['overall', 'red_low', 'red_high', 'green_low', 'green_high']\n",
    "results = {name: {part: {'correct': 0, 'total': 0} for part in partitions} for name in model_dict}\n",
    "\n",
    "# Set models to evaluation mode\n",
    "for model in model_dict.values():\n",
    "    model.eval()\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "print(\"ðŸ“Š Evaluating models...\")\n",
    "with torch.no_grad():\n",
    "    for images, labels, colors in unbiased_val_loader:\n",
    "        batch = images.to(device)\n",
    "        \n",
    "        # Get predictions from both models\n",
    "        preds = {name: torch.max(model(batch), 1)[1] for name, model in model_dict.items()}\n",
    "        \n",
    "        # Collate results for each sample in the batch\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            color = colors[i]\n",
    "            partition_key = f\"{color}_{'high' if label >= 5 else 'low'}\"\n",
    "            \n",
    "            for name, pred_tensor in preds.items():\n",
    "                is_correct = (pred_tensor[i].item() == label)\n",
    "                \n",
    "                # Update partition and overall counts\n",
    "                results[name][partition_key]['correct'] += is_correct\n",
    "                results[name][partition_key]['total'] += 1\n",
    "                results[name]['overall']['correct'] += is_correct\n",
    "                results[name]['overall']['total'] += 1\n",
    "\n",
    "# --- Display Results Table ---\n",
    "print(\"\\n--- Accuracy Comparison: Original vs. Ablated ---\")\n",
    "\n",
    "def calculate_accuracy(data):\n",
    "    if data['total'] == 0:\n",
    "        return 0.0\n",
    "    return (data['correct'] / data['total']) * 100\n",
    "\n",
    "header = f\"{'Partition':<15} | {'Original Model':<22} | {'Ablated Model':<22} | {'Difference':<12}\"\n",
    "print(header)\n",
    "print(\"=\" * len(header))\n",
    "\n",
    "for part in partitions:\n",
    "    original_data = results['Original'][part]\n",
    "    ablated_data = results['Ablated'][part]\n",
    "    \n",
    "    original_acc = calculate_accuracy(original_data)\n",
    "    ablated_acc = calculate_accuracy(ablated_data)\n",
    "    \n",
    "    diff = ablated_acc - original_acc\n",
    "    \n",
    "    original_str = f\"{original_data['correct']}/{original_data['total']} ({original_acc:.1f}%)\"\n",
    "    ablated_str = f\"{ablated_data['correct']}/{ablated_data['total']} ({ablated_acc:.1f}%)\"\n",
    "    \n",
    "    print(f\"{part.replace('_', ' ').title():<15} | {original_str:<22} | {ablated_str:<22} | {diff:+#.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84d1c9d2-76a6-4c10-8ed2-4738b9775a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original': tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9, 9, 9], device='cuda:0'),\n",
       " 'Ablated': tensor([9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 7,\n",
       "         9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9, 9, 9], device='cuda:0')}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aed7f863-2fc2-42e1-9a81-7e6d70451a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluating all three models...\n",
      "\n",
      "--- Accuracy Comparison: Original vs. SAE vs. Ablated ---\n",
      "Partition       | Original               | SAE (Replaced)         | Ablated                | SAE Î”      | Ablated Î” \n",
      "====================================================================================================================\n",
      "Overall         | 3197/6711 (47.6%)      | 3056/6711 (45.5%)      | 3428/6711 (51.1%)      | -2.10% | +3.44%\n",
      "Red Low         | 1698/1764 (96.3%)      | 1614/1764 (91.5%)      | 1522/1764 (86.3%)      | -4.76% | -9.98%\n",
      "Red High        | 0/1608 (0.0%)          | 0/1608 (0.0%)          | 335/1608 (20.8%)       | +0.00% | +20.83%\n",
      "Green Low       | 0/1677 (0.0%)          | 0/1677 (0.0%)          | 126/1677 (7.5%)        | +0.00% | +7.51%\n",
      "Green High      | 1499/1662 (90.2%)      | 1442/1662 (86.8%)      | 1445/1662 (86.9%)      | -3.43% | -3.25%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Assumed variables ---\n",
    "# cnn: Your original trained CNN model\n",
    "# sae: Your trained Faithful_SAE model\n",
    "# ablated_model: The model created with your original create_ablated_model\n",
    "# unbiased_val_loader: The DataLoader for the unbiased validation set\n",
    "# device: Your 'cuda' or 'cpu' device\n",
    "\n",
    "# --- Create the new SAE-Replaced model ---\n",
    "sae_replaced_model = create_sae_replaced_model(cnn, sae, device)\n",
    "\n",
    "# --- Evaluation Setup ---\n",
    "model_dict = {\n",
    "    'Original': cnn,\n",
    "    'SAE (Replaced)': sae_replaced_model,\n",
    "    'Ablated': ablated_model\n",
    "}\n",
    "partitions = ['overall', 'red_low', 'red_high', 'green_low', 'green_high']\n",
    "results = {name: {part: {'correct': 0, 'total': 0} for part in partitions} for name in model_dict}\n",
    "\n",
    "# Set models to evaluation mode\n",
    "for model in model_dict.values():\n",
    "    model.eval()\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "print(\"ðŸ“Š Evaluating all three models...\")\n",
    "with torch.no_grad():\n",
    "    for images, labels, colors in unbiased_val_loader:\n",
    "        batch = images.to(device)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        preds = {name: torch.max(model(batch), 1)[1] for name, model in model_dict.items()}\n",
    "        \n",
    "        # Collate results for each sample in the batch\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            color = colors[i]\n",
    "            partition_key = f\"{color}_{'high' if label >= 5 else 'low'}\"\n",
    "            \n",
    "            for name, pred_tensor in preds.items():\n",
    "                is_correct = (pred_tensor[i].item() == label)\n",
    "                \n",
    "                # Update partition and overall counts\n",
    "                results[name][partition_key]['correct'] += is_correct\n",
    "                results[name][partition_key]['total'] += 1\n",
    "                results[name]['overall']['correct'] += is_correct\n",
    "                results[name]['overall']['total'] += 1\n",
    "\n",
    "# --- Display Results Table ---\n",
    "print(\"\\n--- Accuracy Comparison: Original vs. SAE vs. Ablated ---\")\n",
    "\n",
    "def calculate_accuracy(data):\n",
    "    if data['total'] == 0:\n",
    "        return 0.0\n",
    "    return (data['correct'] / data['total']) * 100\n",
    "\n",
    "header = f\"{'Partition':<15} | {'Original':<22} | {'SAE (Replaced)':<22} | {'Ablated':<22} | {'SAE Î”':<10} | {'Ablated Î”':<10}\"\n",
    "print(header)\n",
    "print(\"=\" * len(header))\n",
    "\n",
    "for part in partitions:\n",
    "    original_data = results['Original'][part]\n",
    "    sae_data = results['SAE (Replaced)'][part]\n",
    "    ablated_data = results['Ablated'][part]\n",
    "    \n",
    "    original_acc = calculate_accuracy(original_data)\n",
    "    sae_acc = calculate_accuracy(sae_data)\n",
    "    ablated_acc = calculate_accuracy(ablated_data)\n",
    "    \n",
    "    sae_diff = sae_acc - original_acc\n",
    "    ablated_diff = ablated_acc - original_acc\n",
    "    \n",
    "    original_str = f\"{original_data['correct']}/{original_data['total']} ({original_acc:.1f}%)\"\n",
    "    sae_str = f\"{sae_data['correct']}/{sae_data['total']} ({sae_acc:.1f}%)\"\n",
    "    ablated_str = f\"{ablated_data['correct']}/{ablated_data['total']} ({ablated_acc:.1f}%)\"\n",
    "    \n",
    "    print(f\"{part.replace('_', ' ').title():<15} | {original_str:<22} | {sae_str:<22} | {ablated_str:<22} | {sae_diff:+#.2f}% | {ablated_diff:+#.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb47a772-4ec3-4c3b-ac8a-d939e9826ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0199, -0.0373, -0.0625,  ..., -0.0618, -0.1308, -0.0772],\n",
       "        [-0.0509,  0.0072,  0.0631,  ..., -0.0484,  0.0748,  0.0504],\n",
       "        [ 0.0215, -0.0079,  0.0697,  ..., -0.0339,  0.0432,  0.0050],\n",
       "        ...,\n",
       "        [ 0.0767, -0.0002,  0.1014,  ..., -0.0099, -0.0533,  0.0427],\n",
       "        [ 0.0334,  0.0177, -0.0490,  ...,  0.0183, -0.0065,  0.0061],\n",
       "        [-0.0670, -0.0131, -0.0083,  ..., -0.0609,  0.0556, -0.0289]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fc1.weight.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09527e5f-a9df-4f6a-b9a7-743aaeb23f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0195, -0.0360, -0.0605,  ..., -0.0585, -0.1310, -0.0720],\n",
       "        [-0.0509,  0.0072,  0.0631,  ..., -0.0484,  0.0748,  0.0504],\n",
       "        [ 0.0434,  0.0088,  0.0719,  ..., -0.0323,  0.1153,  0.0668],\n",
       "        ...,\n",
       "        [ 0.0767, -0.0002,  0.1014,  ..., -0.0099, -0.0533,  0.0427],\n",
       "        [ 0.0270,  0.0018, -0.0600,  ...,  0.0131,  0.0060,  0.0192],\n",
       "        [-0.0294, -0.0140,  0.0376,  ..., -0.0211,  0.0848, -0.0471]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.effective_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdd03f-2ab5-44bb-af4d-4b4b23c07e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
